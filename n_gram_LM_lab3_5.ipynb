{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amulyanrao7777/NLP/blob/main/n_gram_LM_lab3_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e319caf4",
      "metadata": {
        "id": "e319caf4"
      },
      "source": [
        "\n",
        "# N-Gram Language Model  \n",
        "## Smoothing, Perplexity, and Sentence Completion\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79117d50",
      "metadata": {
        "id": "79117d50"
      },
      "source": [
        "\n",
        "## 1. Libraries Used\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "072599e7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "072599e7",
        "outputId": "c986d570-03fe-40d0-fec2-e917d851efef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter\n",
        "import math\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nltk.download('punkt_tab') #punctuation\n",
        "nltk.download('brown') #corpus\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "186ab193",
      "metadata": {
        "id": "186ab193"
      },
      "source": [
        "\n",
        "## 2. Load General-Purpose Corpus (Brown)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c2c14bf2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2c14bf2",
        "outputId": "4b56aa36-957c-4cbf-8bdf-668c9d0a8300"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total words: 981716\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from nltk.corpus import brown\n",
        "\n",
        "words = [w.lower() for w in brown.words() if w.isalpha()]\n",
        "print(\"Total words:\", len(words))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6b5d26d",
      "metadata": {
        "id": "d6b5d26d"
      },
      "source": [
        "\n",
        "## 3. Trainâ€“Test Split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cd79ce03",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd79ce03",
        "outputId": "9c7b471d-6d5b-425a-da84-17a2dde9dcd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 50000\n",
            "Test size: 1000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_words = words[:50000]\n",
        "test_words = words[50000:51000]\n",
        "test_sentence = \" \".join(test_words)\n",
        "\n",
        "print(\"Train size:\", len(train_words))\n",
        "print(\"Test size:\", len(test_words))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c56d732",
      "metadata": {
        "id": "0c56d732"
      },
      "source": [
        "\n",
        "## 4. Build N-Gram Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "07361cf2",
      "metadata": {
        "id": "07361cf2"
      },
      "outputs": [],
      "source": [
        "\n",
        "def build_ngram_model(tokens, n):\n",
        "    ngram_counts = Counter()\n",
        "    context_counts = Counter()\n",
        "\n",
        "    for gram in ngrams(tokens, n):\n",
        "        context = gram[:-1]\n",
        "        ngram_counts[gram] += 1\n",
        "        context_counts[context] += 1\n",
        "\n",
        "    return ngram_counts, context_counts\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a0ff559",
      "metadata": {
        "id": "5a0ff559"
      },
      "source": [
        "\n",
        "## 5. Probability Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7b3a88bf",
      "metadata": {
        "id": "7b3a88bf"
      },
      "outputs": [],
      "source": [
        "\n",
        "def mle_probability(ngram, ngram_counts, context_counts):\n",
        "    context = ngram[:-1]\n",
        "    if context_counts[context] == 0:\n",
        "        return 0\n",
        "    return ngram_counts[ngram] / context_counts[context]\n",
        "\n",
        "def smoothed_probability(ngram, ngram_counts, context_counts, vocab_size):\n",
        "    context = ngram[:-1]\n",
        "    return (ngram_counts[ngram] + 1) / (context_counts[context] + vocab_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fe44d1e",
      "metadata": {
        "id": "8fe44d1e"
      },
      "source": [
        "\n",
        "## 6. Perplexity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e9e2af1d",
      "metadata": {
        "id": "e9e2af1d"
      },
      "outputs": [],
      "source": [
        "\n",
        "def sentence_log_prob(sentence, n, ngram_counts, context_counts, vocab_size, smooth=True):\n",
        "    tokens = [w for w in nltk.word_tokenize(sentence.lower()) if w.isalpha()]\n",
        "    log_prob = 0\n",
        "\n",
        "    for gram in ngrams(tokens, n):\n",
        "        if smooth:\n",
        "            prob = smoothed_probability(gram, ngram_counts, context_counts, vocab_size)\n",
        "        else:\n",
        "            prob = mle_probability(gram, ngram_counts, context_counts)\n",
        "            if prob == 0:\n",
        "                return float('-inf')\n",
        "        log_prob += math.log(prob)\n",
        "\n",
        "    return log_prob\n",
        "\n",
        "\n",
        "def perplexity(sentence, n, ngram_counts, context_counts, vocab_size, smooth=True):\n",
        "    tokens = [w for w in nltk.word_tokenize(sentence.lower()) if w.isalpha()]\n",
        "    N = len(tokens)\n",
        "\n",
        "    log_prob = sentence_log_prob(sentence, n, ngram_counts, context_counts, vocab_size, smooth)\n",
        "\n",
        "    if log_prob == float('-inf'):\n",
        "        return float('inf')\n",
        "\n",
        "    return math.exp(-log_prob / N)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e879658d",
      "metadata": {
        "id": "e879658d"
      },
      "source": [
        "\n",
        "## 7. Train Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d2b275de",
      "metadata": {
        "id": "d2b275de"
      },
      "outputs": [],
      "source": [
        "\n",
        "vocab = set(train_words)\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "models = {}\n",
        "for n in [1, 2, 3, 5, 10]:\n",
        "    models[n] = build_ngram_model(train_words, n)\n",
        "\n",
        "# vocabulary is a subset of corpus --> corpus has duplicates, vocabulary contains only unique words and no duplicates.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c44d4d5b",
      "metadata": {
        "id": "c44d4d5b"
      },
      "source": [
        "\n",
        "## 8. Perplexity Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c22d5880",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c22d5880",
        "outputId": "95a3f435-fbd4-4085-8634-24ce4d55c84c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1-gram model\n",
            "Non-smoothed: inf\n",
            "Smoothed: 1423.2897990857884\n",
            "\n",
            "2-gram model\n",
            "Non-smoothed: inf\n",
            "Smoothed: 4572.492418499444\n",
            "\n",
            "3-gram model\n",
            "Non-smoothed: inf\n",
            "Smoothed: 7509.528848567658\n",
            "\n",
            "5-gram model\n",
            "Non-smoothed: inf\n",
            "Smoothed: 7752.670458088694\n",
            "\n",
            "10-gram model\n",
            "Non-smoothed: inf\n",
            "Smoothed: 7412.500217939968\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for n in models:\n",
        "    counts, contexts = models[n]\n",
        "    print(f\"\\n{n}-gram model\")\n",
        "    print(\"Non-smoothed:\", perplexity(test_sentence, n, counts, contexts, vocab_size, False))\n",
        "    print(\"Smoothed:\", perplexity(test_sentence, n, counts, contexts, vocab_size, True))\n",
        "#why is it that 1gram has the best probability"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "in the above cell,\n",
        "\n",
        "non smoothed-> before laplace smoothing (divided by 0) and inf->infinite\n",
        "\n",
        "smoothed -> after laplace"
      ],
      "metadata": {
        "id": "URHYTpwzF-DG"
      },
      "id": "URHYTpwzF-DG"
    },
    {
      "cell_type": "markdown",
      "id": "78468bee",
      "metadata": {
        "id": "78468bee"
      },
      "source": [
        "\n",
        "## 9. Corpus Size Effect\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "bb23d001",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb23d001",
        "outputId": "325a48e7-d88e-423d-e2bb-8675cb1fb3fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5k perplexity: 7839.723486406142\n",
            "50k perplexity: 7509.528848567658\n"
          ]
        }
      ],
      "source": [
        "# FIX: Use a FIXED vocabulary for fair corpus-size comparison\n",
        "\n",
        "# Fix vocabulary from training data\n",
        "fixed_vocab = set(train_words)\n",
        "fixed_vocab_size = len(fixed_vocab)\n",
        "\n",
        "pp_values = []\n",
        "\n",
        "for label, corpus in [(\"5k\", train_words[:5000]), (\"50k\", train_words[:50000])]:\n",
        "    c_counts, c_ctx = build_ngram_model(corpus, 3)\n",
        "\n",
        "    pp = perplexity(\n",
        "        test_sentence,\n",
        "        3,\n",
        "        c_counts,\n",
        "        c_ctx,\n",
        "        fixed_vocab_size,   # IMPORTANT FIX\n",
        "        smooth=True\n",
        "    )\n",
        "\n",
        "    pp_values.append(pp)\n",
        "    print(label, \"perplexity:\", pp)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2a3a5d6",
      "metadata": {
        "id": "c2a3a5d6"
      },
      "source": [
        "\n",
        "## 10. Sentence Completion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "5d73fad9",
      "metadata": {
        "id": "5d73fad9"
      },
      "outputs": [],
      "source": [
        "\n",
        "def complete_sentence(start_sentence, n, ngram_counts, context_counts, vocab, max_words=20):\n",
        "    tokens = [w for w in nltk.word_tokenize(start_sentence.lower()) if w.isalpha()]\n",
        "    output = tokens.copy()\n",
        "\n",
        "    if len(tokens) >= n - 1:\n",
        "        context = tuple(tokens[-(n-1):])\n",
        "    else:\n",
        "        context = tuple()\n",
        "\n",
        "    for _ in range(max_words):\n",
        "        candidates = []\n",
        "\n",
        "        for word in vocab:\n",
        "            gram = context + (word,)\n",
        "            if gram in ngram_counts:\n",
        "                candidates.append((word, ngram_counts[gram]))\n",
        "\n",
        "        if not candidates and n > 1:\n",
        "          context = context[1:]   # backoff to smaller context\n",
        "          continue\n",
        "\n",
        "        if not candidates:\n",
        "          break\n",
        "\n",
        "        words_, weights = zip(*candidates)\n",
        "        next_word = random.choices(words_, weights=weights)[0]\n",
        "\n",
        "        output.append(next_word)\n",
        "        context = tuple(output[-(n-1):])\n",
        "\n",
        "    return \" \".join(output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bf7b1f9",
      "metadata": {
        "id": "6bf7b1f9"
      },
      "source": [
        "\n",
        "## 12. Generation Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "af2c683c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af2c683c",
        "outputId": "f8b68523-71a1-4fda-a88c-87ab8b1f99c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1-gram completion:\n",
            "the government announced that\n",
            "\n",
            "2-gram completion:\n",
            "the government announced that a teacher now witnessing an engineering in front in the report the group friday emory university bringing them from his time i challenge was among the other seven men agree to arouse those of a second off kunkel bob day hundreds of rumor combined proceeds will sponsor of washington thousands\n",
            "\n",
            "3-gram completion:\n",
            "the government announced that it would force banks to violate their contractual obligations with depositors and undermine the confidence of bank customers if you destroy confidence in following molvar who kept reiterating her request that they tend to be not only reiterated the united states seek instead to detach the castro dragnet that the\n",
            "\n",
            "5-gram completion:\n",
            "the government announced that\n",
            "\n",
            "10-gram completion:\n",
            "the government announced that\n"
          ]
        }
      ],
      "source": [
        "\n",
        "start = \"the government announced that\"\n",
        "\n",
        "for n in [1, 2, 3, 5, 10]:\n",
        "    counts, contexts = models[n]\n",
        "    print(f\"\\n{n}-gram completion:\")\n",
        "    print(complete_sentence(start, n, counts, contexts, vocab, 50))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "start = \"the government announced that they aren't allowing any foreign nationals to go to voyage on any of the coming months of 2026\"\n",
        "\n",
        "for n in [1, 2, 3, 5, 10]:\n",
        "    counts, contexts = models[n]\n",
        "    print(f\"\\n{n}-gram completion:\")\n",
        "    print(complete_sentence(start, n, counts, contexts, vocab,50))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FQai3_zAO22",
        "outputId": "2cd660bb-0b48-409b-df35-3a8da92bf59a"
      },
      "id": "-FQai3_zAO22",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1-gram completion:\n",
            "the government announced that they are allowing any foreign nationals to go to voyage on any of the coming months of\n",
            "\n",
            "2-gram completion:\n",
            "the government announced that they are allowing any foreign nationals to go to voyage on any of the coming months of the jurors said no reason to be done even for popular prices on slim lines each month reporting weight than morton foods stock was driving the mantle and high rate of that it could use the three of the first major american naval announcement that he also criticized bernard gimbel\n",
            "\n",
            "3-gram completion:\n",
            "the government announced that they are allowing any foreign nationals to go to voyage on any of the coming months of were about or extra points in tries during three games on the republicans must hold a public hearing before the trial the announcement of a new record crowd for the gala richard newburger is chairman of the other uncles and aunts the rush butlers the homer robertsons and the players\n",
            "\n",
            "5-gram completion:\n",
            "the government announced that they are allowing any foreign nationals to go to voyage on any of the coming months of\n",
            "\n",
            "10-gram completion:\n",
            "the government announced that they are allowing any foreign nationals to go to voyage on any of the coming months of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Higher N-grams do NOT mean better generation.\n",
        "They mean more precision only when the context has been seen before."
      ],
      "metadata": {
        "id": "XaVMj5vKBXJ-"
      },
      "id": "XaVMj5vKBXJ-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Higher-order N-gram models fail to generate long continuations on unseen sentences due to data sparsity and exact context matching requirements."
      ],
      "metadata": {
        "id": "6f_INYq1BP_U"
      },
      "id": "6f_INYq1BP_U"
    },
    {
      "cell_type": "markdown",
      "id": "6402864a",
      "metadata": {
        "id": "6402864a"
      },
      "source": [
        "\n",
        "## 13. Final Notes\n",
        "\n",
        "- N-gram models suffer from sparsity  \n",
        "- Smoothing is essential  \n",
        "- Higher N does not always mean better\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y7vsKVJdAGm0"
      },
      "id": "y7vsKVJdAGm0",
      "execution_count": 13,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}