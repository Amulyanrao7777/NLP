{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCNVsPPv6mE/jTEow66Z5t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amulyanrao7777/NLP/blob/main/lab4_Assignment_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b52ea546"
      },
      "source": [
        "## Task 1: Sentiment Feature Extractor\n",
        "\n",
        "### Subtask:\n",
        "Implement a Python script using spaCy to extract all (Adjective, Noun) pairs from the provided customer review text.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86acabef"
      },
      "source": [
        "**Reasoning**:\n",
        "The first step is to import the `spacy` library and load the English language model, which is necessary for processing the text and extracting part-of-speech tags.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a12c6fe0",
        "outputId": "5d16391a-8c61-4e72-d1c2-2136fe0f3d17"
      },
      "source": [
        "import spacy\n",
        "\n",
        "# Load the English language model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "print(\"spaCy library imported and 'en_core_web_sm' model loaded.\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spaCy library imported and 'en_core_web_sm' model loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9242062"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the spaCy model is loaded, the next step is to process the `text` variable with the `nlp` model to create a `doc` object. This `doc` object allows for iteration over tokens and access to their part-of-speech tags and lemmas.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c039843",
        "outputId": "4964c3c9-a42a-4458-f275-afc9619f1352"
      },
      "source": [
        "doc = nlp(text)\n",
        "\n",
        "print(\"Text processed by spaCy model.\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text processed by spaCy model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdaa8f59"
      },
      "source": [
        "**Reasoning**:\n",
        "With the text processed into a `doc` object, the next step is to iterate through its tokens, identify adjectives followed by nouns, and store these pairs as lemmas in a list as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f49d361c",
        "outputId": "6efcde8e-2b77-45c9-f7e1-543c056acc44"
      },
      "source": [
        "adj_noun_pairs = []\n",
        "\n",
        "for i, token in enumerate(doc):\n",
        "    # Check if the current token is an adjective\n",
        "    if token.pos_ == 'ADJ':\n",
        "        # Check if there is a next token and if it's a noun\n",
        "        if i + 1 < len(doc) and doc[i+1].pos_ == 'NOUN':\n",
        "            adj_noun_pairs.append((token.lemma_, doc[i+1].lemma_))\n",
        "\n",
        "print(\"Extracted (Adjective, Noun) pairs:\")\n",
        "print(adj_noun_pairs)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted (Adjective, Noun) pairs:\n",
            "[('new', 'phone'), ('fantastic', 'camera')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fa56bb6"
      },
      "source": [
        "## Task 2: GDPR Redactor\n",
        "\n",
        "### Subtask:\n",
        "Create a Python function `redact_sensitive_info(text)` using spaCy that detects and replaces PERSON and GPE entities with '[REDACTED]' from the provided text.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def redact_sensitive_info(text):\n",
        "    doc = nlp(text)\n",
        "    redacted_text = text\n",
        "    # Iterate over entities in reverse order to avoid issues with index changes\n",
        "    for ent in sorted(doc.ents, key=lambda x: x.start_char, reverse=True):\n",
        "        if ent.label_ == 'PERSON' or ent.label_ == 'GPE':\n",
        "            redacted_text = redacted_text[:ent.start_char] + '[REDACTED]' + redacted_text[ent.end_char:]\n",
        "    return redacted_text\n",
        "\n",
        "# Test the function with the provided input text\n",
        "input_text_task2 = \"Startups in Bangalore are growing fast. Mr. Rajesh Kumar met with Sarah Jones in London to discuss the new venture.\"\n",
        "redacted_output = redact_sensitive_info(input_text_task2)\n",
        "\n",
        "print(\"Original Text:\")\n",
        "print(input_text_task2)\n",
        "print(\"\\nRedacted Text:\")\n",
        "print(redacted_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQ081j0ZQhRJ",
        "outputId": "8e3c64a2-a27d-4e88-ff42-17865895124d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            "Startups in Bangalore are growing fast. Mr. Rajesh Kumar met with Sarah Jones in London to discuss the new venture.\n",
            "\n",
            "Redacted Text:\n",
            "Startups in [REDACTED] are growing fast. Mr. [REDACTED] met with [REDACTED] in [REDACTED] to discuss the new venture.\n"
          ]
        }
      ]
    }
  ]
}