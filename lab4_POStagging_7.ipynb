{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTBT8+w3C8I4FV2T6MY8vh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amulyanrao7777/NLP/blob/main/lab4_POStagging_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Mj4O927IEs3v",
        "outputId": "f0b896a3-2d4d-48d7-9769-158c6e9c8947"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- NLTK POS Tagging ---\n",
            "Word            Tag        Description\n",
            "----------------------------------------\n",
            "Apple           NNP       \n",
            "is              VBZ       \n",
            "looking         VBG       \n",
            "at              IN        \n",
            "buying          VBG       \n",
            "U.K.            NNP       \n",
            "startup         NN        \n",
            "for             IN        \n",
            "$               $         \n",
            "1               CD        \n",
            "billion         CD        \n",
            ".               .         \n",
            "\n",
            "--- spaCy POS Tagging ---\n",
            "Word            POS        Tag        Explanation\n",
            "------------------------------------------------------------\n",
            "Apple           PROPN      NNP        noun, proper singular\n",
            "is              AUX        VBZ        verb, 3rd person singular present\n",
            "looking         VERB       VBG        verb, gerund or present participle\n",
            "at              ADP        IN         conjunction, subordinating or preposition\n",
            "buying          VERB       VBG        verb, gerund or present participle\n",
            "U.K.            PROPN      NNP        noun, proper singular\n",
            "startup         VERB       VBD        verb, past tense\n",
            "for             ADP        IN         conjunction, subordinating or preposition\n",
            "$               SYM        $          symbol, currency\n",
            "1               NUM        CD         cardinal number\n",
            "billion         NUM        CD         cardinal number\n",
            ".               PUNCT      .          punctuation mark, sentence closer\n",
            "\n",
            "--- Named Entity Recognition ---\n",
            "Entity               Label      Explanation\n",
            "------------------------------------------------------------\n",
            "Elon Musk            PERSON     People, including fictional\n",
            "2002                 DATE       Absolute or relative dates or periods\n",
            "California           GPE        Countries, cities, states\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Elon Musk\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " founded SpaceX in \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2002\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ". It is based in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    California\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ".</div></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Visualization saved to 'ner_visualization.html'\n",
            "--- Evaluation Metrics ---\n",
            "\n",
            "Accuracy: 0.86\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ADJ       0.00      0.00      0.00         1\n",
            "         DET       1.00      1.00      1.00         1\n",
            "        NOUN       0.67      1.00      0.80         2\n",
            "         ORG       1.00      1.00      1.00         1\n",
            "       PUNCT       1.00      1.00      1.00         1\n",
            "        VERB       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.86         7\n",
            "   macro avg       0.78      0.83      0.80         7\n",
            "weighted avg       0.76      0.86      0.80         7\n",
            "\n",
            "\n",
            "Analysis:\n",
            "Notice how the ADJ tag has 0.00 precision/recall because our model missed it entirely.\n",
            "The NOUN tag has high recall but lower precision because we over-predicted it.\n",
            "\n",
            "--- Most Frequent Organizations (ORG) in Text ---\n",
            "Apple Inc.                Count: 1\n",
            "Google                    Count: 1\n",
            "Microsoft                 Count: 1\n",
            "Amazon                    Count: 1\n",
            "Meta                      Count: 1\n",
            "the European Union        Count: 1\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('universal_tagset')\n",
        "\n",
        "# ==========================================\n",
        "# PART 1: POS TAGGING\n",
        "# ==========================================\n",
        "\n",
        "sample_text = \"Apple is looking at buying U.K. startup for $1 billion.\"\n",
        "\n",
        "# ------------------------------------------\n",
        "# APPROACH 1: Using NLTK (Rule-based/Stochastic)\n",
        "# ------------------------------------------\n",
        "print(\"--- NLTK POS Tagging ---\")\n",
        "\n",
        "# Step 1: Tokenization\n",
        "tokens = nltk.word_tokenize(sample_text)\n",
        "\n",
        "# Step 2: Tagging\n",
        "# NLTK uses the Penn Treebank tagset by default (NN, VB, JJ, etc.)\n",
        "nltk_tags = nltk.pos_tag(tokens)\n",
        "\n",
        "print(f\"{'Word':<15} {'Tag':<10} {'Description'}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "for word, tag in nltk_tags:\n",
        "    print(f\"{word:<15} {tag:<10}\")\n",
        "\n",
        "# ------------------------------------------\n",
        "# APPROACH 2: Using spaCy (Deep Learning based)\n",
        "# ------------------------------------------\n",
        "print(\"\\n--- spaCy POS Tagging ---\")\n",
        "\n",
        "# Load the small English model\n",
        "# Run in terminal first: python -m spacy download en_core_web_sm\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Process the text\n",
        "doc = nlp(sample_text)\n",
        "\n",
        "print(f\"{'Word':<15} {'POS':<10} {'Tag':<10} {'Explanation'}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for token in doc:\n",
        "    # token.pos_ is the coarse-grained tag (Universal POS)\n",
        "    # token.tag_ is the fine-grained tag (Penn Treebank)\n",
        "    print(f\"{token.text:<15} {token.pos_:<10} {token.tag_:<10} {spacy.explain(token.tag_)}\")\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# PART 2: NAMED ENTITY RECOGNITION (NER)\n",
        "# ==========================================\n",
        "\n",
        "ner_text = \"Elon Musk founded SpaceX in 2002. It is based in California.\"\n",
        "\n",
        "# Process text\n",
        "doc_ner = nlp(ner_text)\n",
        "\n",
        "print(f\"\\n--- Named Entity Recognition ---\")\n",
        "print(f\"{'Entity':<20} {'Label':<10} {'Explanation'}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for ent in doc_ner.ents:\n",
        "    print(f\"{ent.text:<20} {ent.label_:<10} {spacy.explain(ent.label_)}\")\n",
        "\n",
        "# --- VISUALIZATION ---\n",
        "# If running in Jupyter Notebook, use:\n",
        "displacy.render(doc_ner, style=\"ent\", jupyter=True)\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nVisualization saved to 'ner_visualization.html'\")\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# PART 3: EVALUATION METRICS\n",
        "# ==========================================\n",
        "\n",
        "# 'y_true' represents the actual correct tags for a sentence\n",
        "# 'y_pred' represents what our model predicted\n",
        "# Example Sentence: \"Google is a big company\"\n",
        "# Correct Tags:     [ORG, VERB, DET, ADJ, NOUN]\n",
        "\n",
        "y_true = [\"ORG\", \"VERB\", \"DET\", \"ADJ\", \"NOUN\", \"NOUN\", \"PUNCT\"]\n",
        "y_pred = [\"ORG\", \"VERB\", \"DET\", \"NOUN\", \"NOUN\", \"NOUN\", \"PUNCT\"]\n",
        "# Note the error: The model predicted \"big\" (ADJ) as a \"NOUN\"\n",
        "\n",
        "print(\"--- Evaluation Metrics ---\\n\")\n",
        "\n",
        "# 1. Accuracy\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# 2. Classification Report (Precision, Recall, F1)\n",
        "# This generates a table showing metrics for every single tag type\n",
        "report = classification_report(y_true, y_pred, zero_division=0)\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(report)\n",
        "\n",
        "print(\"\\nAnalysis:\")\n",
        "print(\"Notice how the ADJ tag has 0.00 precision/recall because our model missed it entirely.\")\n",
        "print(\"The NOUN tag has high recall but lower precision because we over-predicted it.\")\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# STUDENT CHALLENGE: Entity Frequency Counter\n",
        "# ==========================================\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "# Paste any news paragraph here\n",
        "news_text = \"\"\"\n",
        "Apple Inc. and Google are among the top technology companies in the United States.\n",
        "Microsoft also announced a partnership with OpenAI in San Francisco.\n",
        "Amazon reported record earnings, while Meta faced scrutiny from the European Union.\n",
        "\"\"\"\n",
        "\n",
        "doc_news = nlp(news_text)\n",
        "\n",
        "# Extract only ORG entities\n",
        "org_entities = [ent.text for ent in doc_news.ents if ent.label_ == \"ORG\"]\n",
        "org_counts = Counter(org_entities)\n",
        "\n",
        "print(\"\\n--- Most Frequent Organizations (ORG) in Text ---\")\n",
        "for org, count in org_counts.most_common():\n",
        "    print(f\"{org:<25} Count: {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a-ZXLausEtkG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}